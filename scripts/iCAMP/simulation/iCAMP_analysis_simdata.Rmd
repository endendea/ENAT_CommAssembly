---
title: "Community Assembly Analysis with iCAMP"
author: "ENAT"
date: "2025-06-09"
output: html_document
---

# Community assembly analysis with iCAMP
## Project info
```{r , eval=TRUE, echo=T, include=T, message=FALSE, warning=FALSE}

library(here)

# set optional parameters
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE, 
                      root.dir = here())
options(scipen = 999, digits = 3)

```

```{r loading libraries, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

## load required packages
library(Hmisc)
library(phyloseq)
library(qiime2R)
library(tidyverse)
library(magrittr)
library(devtools)
library(qiime2R)
library(here)
library(breakaway)
library(DivNet)
library(ape)
library(vegan)
library(ggtext)
library(cowplot)
library(RColorBrewer)
library(microbiome)
library(lme4)
library(lmerTest)
library(decontam)
library(glue)
library(lubridate)
library(DECIPHER)
library(ensembleTax)
library(ggh4x)
library(RColorBrewer)
library(dplyr)


library(iCAMP)
library(permute)
library(bigmemory)
library(nortest)
library(minpack.lm)
library(DirichletReg)
library(data.table)
library(NST)
library(RVAideMemoire)

source(here("scripts", "iCAMP", "handytool.r"))

```

## iCAMP analysis

### key parameter settings
``` {r key parameters setting, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

save.wd <- here("results", "output_data", "iCAMP_simdata")
if (!dir.exists(save.wd)){dir.create(save.wd)}
rand.time = 250 # randomization time, 1000 is usually enough.
nworker=1 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
memory.G=50 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.

```


``` {r input data preparation, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

### Loop through simulated data
dir.prefixs = list.dirs(path = here("data", "processed", "SimulatedData", "NoComp"), recursive = TRUE)[-1]
for(x in 1:length(dir.prefixs)){
  dir.prefixi=dir.prefixs[x]
  prefixs = list.files(dir.prefixi)
  print(prefixs)
  for (i in 1:length(prefixs)){
    sim.prefix=prefixs[i] 
    print(sim.prefix)
    prefix = sub("\\.comm.*$", "", sim.prefix)
    print(paste("prefix:", prefix))

    load(file.path(dir.prefixi, sim.prefix))
    
    comm <- sim.data$comm
    #clas <- as.data.frame(tax_table(psdata_AB48))
    pd <- sim.data$pd
    tree <- sim.data$tree
    treat = data.frame(sampname = c(paste0("Almere_butyrate", 1:5), paste0("Bath_butyrate", 1:5),
                                    paste0("Almere_acetate", 1:5), paste0("Bath_acetate", 1:5))) %>%
      mutate(sludge_source.substrate = str_remove(sampname, "[0-9]+$"))
    
    #set sampname as rownames
    rownames(treat) <- treat$sampname
    treat$sampname <- NULL
    
    ############################################################
    
    ### Match sample IDs in OTU table and treatment information table
    
    sampid.check = match.name(rn.list=list(comm=comm, treat=treat))
    # for the example data, the output should be All match very well.
    # for your data files, if you have not matched their IDs, the unmatched samples will be removed.
    treat = sampid.check$treat
    comm = sampid.check$comm
    comm = comm[,colSums(comm)>0,drop=FALSE] # if some unmatched samples were removed, some OTUs may become ghosts, then you may use this line to remove them if necessary.
    
    ##########################################################
    
    ### Match OTU IDs in OTU table and tree file
    
    spid.check = match.name(cn.list=list(comm=comm),
                             tree.list = list(tree=tree))
    # for the example data, the output should be "All match very well".
    # for your data files, if you have not matched the IDs before, the unmatched OTUs will be removed.
    comm = spid.check$comm
    #clas = spid.check$clas
    tree = spid.check$tree
  
    ##################################################
    
    ### Calculate pairwise phylogenetic distance matrix.
    
    save.wdsub = file.path(save.wd, prefix)
    dir.create(save.wdsub, recursive = TRUE)
    
    setwd(save.wdsub)
    if(!file.exists("pd.desc"))  # pd is short for phylogenetic distance
    {
      pd.big = iCAMP::pdist.big(tree = tree, wd=save.wdsub, nworker = nworker, memory.G = memory.G)
      # output files:
      # path.rda: a R object to list all the nodes and  edge lengthes from root to every tip. saved in R data format. an intermediate output when claculating phylogenetic distance matrix.
      # pd.bin: BIN file (backingfile) generated by function big.matrix in R package bigmemory. This is the big matrix storing pairwise phylogenetic distance values. By using this bigmemory format file, we will not need memory but hard disk when calling big matrix for calculation.
      # pd.desc: the DESC file (descriptorfile) to hold the backingfile (pd.bin) description.
      # pd.taxon.name.csv: comma delimited csv file storing the IDs of tree tips (OTUs), serving as the row/column names of the big phylogenetic distance matrix.
    }else{
      # if you already calculated the phylogenetic distance matrix in a previous run
      pd.big = list()
      pd.big$tip.label = read.csv(paste0(save.wdsub,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
      pd.big$pd.wd = save.wdsub
      pd.big$pd.file = "pd.desc"
      pd.big$pd.name.file = "pd.taxon.name.csv"
      print("finish calculating pd")
    }
    
    ##########################################################
    icbin_comp = list()
    bsz = c(12, 24, 48)
    ### calculate iCAMP result 
    
    for (j in bsz){
      
      bin.size.limit = j # For real data, usually use a proper number according to phylogenetic signal test or try some settings then choose the reasonable stochasticity level. our experience is 12, or 24, or 48. 
      sig.index="SES.RC" # see other options in help document of icamp.big.
      icres=iCAMP::icamp.big(comm=comm, pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label,
                             pd.wd = pd.big$pd.wd, rand = rand.time, tree=tree,
                             prefix = prefix, ds = 0.2, pd.cut = NA, sp.check = TRUE,
                             phylo.rand.scale = "within.bin", taxa.rand.scale = "across.all",
                             phylo.metric = "bMPD", sig.index=sig.index, bin.size.limit = bin.size.limit, 
                             nworker = nworker, memory.G = memory.G, rtree.save = FALSE, detail.save = TRUE, 
                             qp.save = FALSE, detail.null = TRUE, ignore.zero = TRUE, output.wd = save.wdsub, 
                             correct.special = TRUE, unit.sum = rowSums(comm), special.method = "Simple",
                             ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",meta.ab = NULL)
      
      save.file(icres$bNRIiRCa,prefix=prefix, folder= save.wdsub, filename = paste0("bin.size", bin.size.limit, ".ProcessImp.Pairwise.bNRIi.RCa"))
      print("finish calculating icres")
      
      ############################################
      
      ### iCAMP bin-level statistics 
      
      treat.use=treat[,"sludge_source.substrate",drop=FALSE]
      treats=data.frame(CountAll="All", treat.use,stringsAsFactors = FALSE)
      icbin=icamp.bins(icamp.detail = icres$detail,treat = treats,boot = TRUE, rand.time = 1000)
      save(icbin,file = file.path(save.wdsub, paste0(prefix, "bin.size", bin.size.limit,  "BinSummaryDetail.rda")))
      print("finish calculating icbin")
      
      Pt=icbin$Pt
      Ptk=icbin$Ptk
      BPtk=icbin$BPtk
      BRPtk=icbin$BRPtk
      #clas.bin=icbin$Class.Bin
      #bin.clas=icbin$Bin.TopClass
      Binwt=icbin$Binwt
      
      save.file(Pt,prefix = paste0(prefix, "_", bin.size.limit), folder=save.wdsub, filename = paste0("_bin.size", bin.size.limit, "_ProcessImpCom.Pt"))
      save.file(Ptk,prefix = paste0(prefix, "_", bin.size.limit),folder=save.wdsub, filename = paste0("_bin.size", bin.size.limit, "_ProcessImpBin.Ptk"))
      save.file(BPtk,prefix = paste0(prefix, "_", bin.size.limit), folder=save.wdsub, filename = paste0("_bin.size", bin.size.limit, "_BinContrProcess.BPtk"))
      save.file(BRPtk,prefix = paste0(prefix, "_", bin.size.limit), folder=save.wdsub, filename = paste0("_bin.size", bin.size.limit,"BinRelContrProcess.BRPtk"))
      #save.file(clas.bin,prefix = paste0(prefix, "_", bin.size.limit),folder=save.wdsub, filename = "OTUBinClass")
      #save.file(bin.clas,prefix = paste0(prefix, "_", bin.size.limit),folder=save.wdsub, filename = "BinTopOTU")
      save.file(Binwt,prefix = paste0(prefix, "_", bin.size.limit),folder=save.wdsub, filename = paste0("_bin.size", bin.size.limit,"_BinRelAbundance"))
      
      
      ## Visualize processes relative important in each group: icbin$Pt as source data
      
      barp <- icbin$Pt %>%
        filter(Group != "All") %>%
        pivot_longer(cols = 4:ncol(.),
                     names_to = "Process", 
                     values_to = "Relative_importance") %>%
        mutate(Relative_importance = as.numeric(Relative_importance)) %>%
        ggplot(aes(x = Group, y = Relative_importance, fill = Process)) +
        geom_bar(stat = "identity", position = "fill") +
        scale_y_continuous(labels = scales::percent) +
        scale_fill_manual(values = c("#FFA000", "#21455e",
                                     "#D0D1E6", "#FFEE58",
                                     "#7492CF")) +
        labs(y = "Relative importance (%)", x = NULL) +
        theme_minimal() +
        theme(
          axis.text.x = element_text(size = 14, angle = 45, hjust = 1),   # X-axis text size
          axis.text.y = element_text(size = 14),   # Y-axis text size
          axis.title.y = element_text(size = 16),  # Y-axis title size
          legend.text = element_text(size = 12),   # Legend text size
          legend.title = element_text(size = 14)   # Legend title size
        )
      
      print(barp)
    
      # save plots
      ggsave(plot = barp, 
             filename = file.path(save.wdsub, paste0(prefix, "_bin.size", bin.size.limit, "_summary_process_relimp.pdf")), width = 6 , height = 6)
      
      icbin$Pt$bin.size.limit <- bin.size.limit
      icbin_comp[[i]] <- icbin$Pt
    }
    icbin_comp_df <- dplyr::bind_rows(icbin_comp)
    write.csv(icbin_comp_df, file = file.path(save.wdsub, "icbin_comp_summary.csv"), row.names = FALSE)
  }
}

```

## For iToL

### genus abundance for iToL

``` {r PhaCmessage=F, echo=T, eval=T, warning=F, include=T, cache=T}

# agglomerate taxa to genus level
psdata_AB_genus <- psdata_AB48 %>%
  tax_glom(., "Genus")

library(ape)

# save new tree
new_tree <- phy_tree(psdata_AB_genus)

# Save the data for making PhaC list
saveRDS(psdata_AB_genus, file = here("data", "processed", "for_iCAMP", "YXIN_psdata_AB_genus.rds"))

# Save to Newick format
write.tree(new_tree, file = paste0(save.wd, "/YXIN_AB_genus_output_tree.newick"))

# add column ASV to the AB_clas.bin
AB_clas.bin_genus <- AB_clas.bin %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV, Bin, Genus) %>%
  mutate(Bin = tolower(Bin))

# melt the phyloseq object into a df-like structure
ps_genus <- psmelt(psdata_AB_genus) %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )


# count n genera n = 426
ps_genus %>% 
  as_tibble() %>% 
  mutate(Genus = factor(Genus)) %>% 
  pull(Genus) %>% 
  levels() %>% 
  length() 
  
# merge ASV and Bin data
ASV_table <- tax_table(psdata_AB_genus) %>%
  as.data.frame() %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV) %>%
  left_join(AB_clas.bin_genus, by = "ASV") %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )
  
# Loop

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)
substrate_list <- unique(ps_genus$substrate)

for (grp in source_list) {
  for (subs in substrate_list) {
    # Create a unique key for each combination
    list_key <- paste(grp, subs, sep = "_")
    
    # Filter and normalize abundance within each Sample
    abundance_list[[list_key]] <- ps_genus %>% 
      filter(sludge_source == grp, substrate == subs) %>% 
      select(Sample, Abundance, Genus) %>%
      left_join(ASV_table, by = "Genus") %>%
      group_by(Sample, Genus) %>%
      summarise(Abundance = sum(Abundance), .groups = "drop_last") %>%
      mutate(Abundance = Abundance / sum(Abundance) * 100) %>%
      ungroup() %>%
      mutate(SludgeSource = grp, Substrate = subs) %>%
      left_join(ASV_table, by = "Genus")
  }
}

# Combine to one long data frame
abundance_all <- bind_rows(abundance_list)

# Or save as TSV
write.table(abundance_all, paste0(save.wd, "/YXIN_AB_genus_abundances.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)

```

### Preparing comm assembly data for iToL
``` {r extract phylo tree for iToL, message=F, echo=T, eval=T, warning=F, include=T, cache=T}}


Ptk_list <- list()
group_list <- unique(AB_Ptk$Group)

for (grp in group_list) {
  Ptk_list[[grp]] <- AB_Ptk %>%
    as.data.frame() %>%
    filter(Index %in% c("HeS", "HoS", "DL", "HD", "DR")) %>%
    filter(Group == grp) %>%
    pivot_longer(cols = 5:ncol(.),
                 names_to = "Bin",
                 values_to = "Importance") %>%
    pivot_wider(names_from = "Index",
                values_from = "Importance") %>%
    select(Bin:DR) %>%
    mutate(Group = grp) %>%
    right_join(ASV_table, by = "Bin")
}

# Combine if needed
Ptk_all <- bind_rows(Ptk_list)

# Or save as TSV
write.table(Ptk_all, paste0(save.wd, "/YXIN_48h_ProcImp_iToL.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)


```


``` {r PhaC, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

phac <- read_tsv(here("data", "processed", "for_iCAMP", "PhaC_kegg_gtdb.txt"))

phac_data <- tax_table(psdata_AB_genus) %>%
  as.data.frame() %>%
  mutate(ASV = rownames(.)) %>%
  left_join(., phac, by = "Genus" )

# save the data for iToL
write.table(phac_data, file = glue(save.wd, "/AB_phac_genus_level.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)

```


### iToL data with genus ID as tip labels

``` {r iToL format }

# Get unique Bin names
Bin_names <- unique(ASV_table$Bin)

# Generate distinct colors for each Bin
# You can use RColorBrewer, viridis, or base colors
library(RColorBrewer)
n_bins <- length(Bin_names)
color_vector <- brewer.pal(min(n_bins, 8), "Set2")  # Use Set2 palette (up to 8 colors)
if (n_bins > 8) {
  # If more than 8 bins, extend using colorRampPalette
  color_vector <- colorRampPalette(brewer.pal(8, "Set2"))(n_bins)
}

# Create a named vector
bin_colors <- setNames(color_vector, Bin_names)
bin_colors_df <- tibble(Bin = names(bin_colors), color = unname(bin_colors))

# Build legend lines for iTOL format
legend_colors <- paste(unname(bin_colors), collapse = "\t")
legend_labels <- paste(names(bin_colors), collapse = "\t")


# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tGenus_Bins",
  "LEGEND_TITLE\tBins",
  glue("LEGEND_COLORS\t{legend_colors}"),
  glue("LEGEND_LABELS\t{legend_labels}"),
  "DATA"
)

# Join color info into your data
df <- ASV_table %>%
  left_join(bin_colors_df, by = "Bin") %>%
  select(Genus, color, Bin)

# Set the output path
output_file <- glue("{save.wd}/iToL_Bins_og_genusID.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)

#####################################################
# Relative importance

relImp_list <- list()
grp_list <- unique(Ptk_all$Group)

for (grp in grp_list) {
  df <- Ptk_all %>%
    filter(Group == grp) %>%
    select(ASV, HeS:DR) %>%
    left_join(ASV_table, by = "ASV" ) %>%
    select(Genus, HeS:DR)
    
  # Get dynamic sample names
  index_cols <- colnames(df)[-1]  # Assuming ASV is the first column
  index_labels <- paste(index_cols, collapse = "\t")
      
  # Create header lines with glue for dynamic text
  header_lines <- c(
    "DATASET_MULTIBAR",
    "SEPARATOR\tTAB",
    glue("DATASET_LABEL\tProcess Relative Importance {grp}"),
    glue("FIELD_LABELS\t{index_labels}"),
    "FIELD_COLORS\t#FFEE58\t#7492CF\t#FFA000\t#D0D1E6\t#21455e",
    "DATASET_SCALE\t100\t100\t100\t100\t100",
    "DATA"
  )
    
  # Set the output path
  output_file <- glue("{save.wd}/iToL_{grp}_relImp_og_genusID.tsv")
    
  # Write header and data
  writeLines(header_lines, con = output_file)
  write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
  # Store to list if needed
  relImp_list[[grp]] <- df
  }

#########################################################

# Heatmap for genus abundance per sample

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)
substrate_list <- unique(ps_genus$substrate)

for (grp in source_list) {
  for (subs in substrate_list) {

    # Create a unique key for the list
    list_key <- paste(grp, subs, sep = "_")
    
    df <- abundance_all %>%
      filter(SludgeSource == grp, Substrate == subs) %>%
      select(Genus, Sample, Abundance) %>%
      pivot_wider(names_from = Sample, values_from = Abundance)

    # Get dynamic sample names
    sample_cols <- colnames(df)[-1]  # Assuming ASV is the first column
    sample_labels <- paste(sample_cols, collapse = "\t")
    
    # Create header lines with glue for dynamic text
    header_lines <- c(
      "DATASET_HEATMAP",
      "SEPARATOR\tTAB",
      glue("DATASET_LABEL\tAbundance per sample {grp} {subs}"),
      glue("FIELD_LABELS\t{sample_labels}"),
      "COLOR_MIN\t#FFFFFF",
      "COLOR_MAX\t#FF0000",
      "USE_MID_COLOR\t1",
      "COLOR_MID\t#FF8080",
      "DATA"
    )
    
    # Set the output path
    output_file <- glue("{save.wd}/iToL_{grp}_{subs}_abundance_og_genusID.tsv")
    
    # Write header and data
    writeLines(header_lines, con = output_file)
    write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
    # Store to list if needed
    abundance_list[[list_key]] <- df
  }
}

# Phac Status

phac <- read_tsv(here("data", "processed", "for_iCAMP", "PhaC_kegg_gtdb_ver16June.txt"))

phac_status <- c("YES", "Unknown")
phac_col <- c("#81C784", "#E0E0E0")

df <- phac %>%
  left_join(ASV_table, by = "Genus") %>%
  mutate(color = case_when(
    PhaC_status == "YES" ~ phac_col[1],
    PhaC_status == "Unknown" ~ phac_col[2])) %>%
  select(Genus, color, PhaC_status)

# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tPhaC16June",
  "LEGEND_TITLE\tPhaC status",
  glue("LEGEND_COLORS\t{glue_collapse(phac_col, sep = '\t')}"),
  glue("LEGEND_LABELS\t{glue_collapse(phac_status, sep = '\t')}"),
  "DATA"
)

# Set the output path
output_file <- glue("{save.wd}/iToL_PhaC_status.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)

```

```{r}

Sel100 = load("C:/Dea/Master/Internship/Microbial ecology of PHA production from activated sludge/ENAT_CommAssembly/data/processed/simulatedData/NoComp/BMb12d02/BMb12d02.S1.Sel.comm.tree.pd.ABP.rda")

comm = sim.data$comm

```









