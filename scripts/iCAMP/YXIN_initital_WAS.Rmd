---
title: "Community Assembly Analysis with iCAMP"
author: "ENAT"
date: "2025-06-09"
output: html_document
---

# Community assembly analysis with iCAMP
## Project info
```{r , eval=TRUE, echo=T, include=T, message=FALSE, warning=FALSE}

library(here)

# set optional parameters
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE, 
                      root.dir = here())
options(scipen = 999, digits = 3)

```

```{r loading libraries, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

## load required packages
library(Hmisc)
library(phyloseq)
library(qiime2R)
library(tidyverse)
library(magrittr)
library(devtools)
library(qiime2R)
library(here)
library(breakaway)
library(DivNet)
library(ape)
library(vegan)
library(ggtext)
library(cowplot)
library(RColorBrewer)
library(microbiome)
library(lme4)
library(lmerTest)
library(decontam)
library(glue)
library(lubridate)
library(DECIPHER)
library(ensembleTax)
library(ggh4x)
library(RColorBrewer)
library(dplyr)


library(iCAMP)
library(permute)
library(bigmemory)
library(nortest)
library(minpack.lm)
library(DirichletReg)
library(data.table)
library(NST)
library(RVAideMemoire)

source(here("scripts", "iCAMP", "handytool.r"))

```

## iCAMP analysis (INITIAL WAS)

### key parameter settings
``` {r key parameters setting, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

prefix = "YXIN_0h" # prefix of the output file names. usually use a project ID.
rand.time = 250 # randomization time, 1000 is usually enough.
nworker=1 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
memory.G=50 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.

```

### Select data: initial WAS only
``` {r input data preparation, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

psdata_INIT <- readRDS(here("data", "processed" , "for_iCAMP", "YXIN_psdata_INIT.rds"))

comm <- t(as.data.frame(otu_table(psdata_INIT)))
clas <- as.data.frame(tax_table(psdata_INIT))
treat <- as(sample_data(psdata_INIT), "data.frame") %>%
  select(sludge_source, substrate) %>%
  mutate(exp = substr(rownames(.), 1, 4)) %>%
  mutate(exp.source = paste(exp, sludge_source, sep = "_")) %>%
  mutate(exp.source.substrate = paste(exp, sludge_source, substrate, sep = "_"))
tree <- phy_tree(psdata_INIT)

```

### Match sample IDs in OTU table and treatment information table

``` {r merge seqs & metadata, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

sampid.check = match.name(rn.list=list(comm=comm, treat=treat))
# for the example data, the output should be All match very well.
# for your data files, if you have not matched their IDs, the unmatched samples will be removed.
treat = sampid.check$treat
comm = sampid.check$comm
comm = comm[,colSums(comm)>0,drop=FALSE] # if some unmatched samples were removed, some OTUs may become ghosts, then you may use this line to remove them if necessary.

```

### Match OTU IDs in OTU table and tree file

``` {r match OTUs table with tree, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

spid.check = match.name(cn.list=list(comm=comm), rn.list = list(clas=clas),
                         tree.list = list(tree=tree))
# for the example data, the output should be "All match very well".
# for your data files, if you have not matched the IDs before, the unmatched OTUs will be removed.
comm = spid.check$comm
clas = spid.check$clas
tree = spid.check$tree

```

### Calculate pairwise phylogenetic distance matrix.

``` {r calculate phylogenetic distance matrix, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

# since microbial community data usually has a large number of species (OTUs or ASVs), we use "big.matrix" in R package "bigmemory" to handle the large phylogenetic distance matrix. 

dir.create(here("results", "output_data", "iCAMP_0h"), recursive = TRUE)
save.wd <- here("results", "output_data", "iCAMP_0h")

setwd(save.wd)
if(!file.exists("pd.desc"))  # pd is short for phylogenetic distance
{
  pd.big = iCAMP::pdist.big(tree = tree, wd=save.wd, nworker = nworker, memory.G = memory.G)
  # output files:
  # path.rda: a R object to list all the nodes and  edge lengthes from root to every tip. saved in R data format. an intermediate output when claculating phylogenetic distance matrix.
  # pd.bin: BIN file (backingfile) generated by function big.matrix in R package bigmemory. This is the big matrix storing pairwise phylogenetic distance values. By using this bigmemory format file, we will not need memory but hard disk when calling big matrix for calculation.
  # pd.desc: the DESC file (descriptorfile) to hold the backingfile (pd.bin) description.
  # pd.taxon.name.csv: comma delimited csv file storing the IDs of tree tips (OTUs), serving as the row/column names of the big phylogenetic distance matrix.
}else{
  # if you already calculated the phylogenetic distance matrix in a previous run
  pd.big = list()
  pd.big$tip.label = read.csv(paste0(save.wd,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
  pd.big$pd.wd = save.wd
  pd.big$pd.file = "pd.desc"
  pd.big$pd.name.file = "pd.taxon.name.csv"
}

```

### Estimate community assembly process with pNST to choose the best nmin

```{r, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

# pNST
prefixj=paste0(prefix,".pNST")
treat.use=treat[,"exp.source",drop=FALSE]
pnstout=NST::pNST(comm=comm, pd.desc=pd.big$pd.file,
                  pd.wd=pd.big$pd.wd, pd.spname=pd.big$tip.label,
                  group=treat.use, abundance.weighted=TRUE,
                  rand=1000,output.rand=FALSE, taxo.null.model="PF",
                  phylo.shuffle=TRUE, nworker=nworker,
                  between.group=TRUE, SES=TRUE,RC=TRUE)
save(pnstout,file = here("results", "output_data", "iCAMP_0h", paste0(prefixj,".detail.rda")))
save.file(pnstout$index.grp,prefix=prefix,folder = save.wd, filename = "pNST.group.summary")
save.file(pnstout$index.pair.grp,prefix=prefix,folder = save.wd, filename = "pNST.pairwise")

```

### calculate iCAMP result (initial was)
``` {r iCAMP analysis, message=F, echo=T, eval=T, warning=F, include=T, cache=T}



bin.size.limit = 24 # For real data, usually use a proper number according to phylogenetic signal test or try some settings then choose the reasonable stochasticity level. our experience is 12, or 24, or 48. 
sig.index="SES.RC" # see other options in help document of icamp.big.
INIT_icres=iCAMP::icamp.big(comm=comm, pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label,
                       pd.wd = pd.big$pd.wd, rand = rand.time, tree=tree,
                       prefix = prefix, ds = 0.2, pd.cut = NA, sp.check = TRUE,
                       phylo.rand.scale = "within.bin", taxa.rand.scale = "across.all",
                       phylo.metric = "bMPD", sig.index=sig.index, bin.size.limit = bin.size.limit, 
                       nworker = nworker, memory.G = memory.G, rtree.save = FALSE, detail.save = TRUE, 
                       qp.save = FALSE, detail.null = TRUE, ignore.zero = TRUE, output.wd = save.wd, 
                       correct.special = TRUE, unit.sum = rowSums(comm), special.method = "Simple",
                       ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",meta.ab = NULL)

save.file(INIT_icres$bNRIiRCa,prefix=prefix,filename = "INIT_ProcessImp.Pairwise.bNRIi.RCa")

```

### iCAMP bin-level statistics (initial WAS)
```{r iCAMP bin-level stats, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

treat.init=treat[,"exp.source",drop=FALSE]
treats=data.frame(CountAll="All", treat.init,stringsAsFactors = FALSE)
INIT_icbin=icamp.bins(icamp.detail = INIT_icres$detail,treat = treats,
                 clas = clas,boot = TRUE, rand.time = 1000)
save(INIT_icbin,file = here("results", "output_data", "iCAMP_0h", paste0(prefix, "_iCAMPBinSummaryDetail.rda")))

INIT_Ptk=INIT_icbin$Ptk
INIT_BPtk=INIT_icbin$BPtk
INIT_BRPtk=INIT_icbin$BRPtk
INIT_clas.bin=INIT_icbin$Class.Bin
INIT_bin.clas=INIT_icbin$Bin.TopClass
INIT_Binwt=INIT_icbin$Binwt

save.file(INIT_Ptk,prefix=prefix,folder=save.wd, filename = "ProcessImpBin.Ptk", )
save.file(INIT_BPtk,prefix=prefix, folder=save.wd, filename = "BinContrProcess.BPtk")
save.file(INIT_BRPtk,prefix=prefix, folder=save.wd, filename = "BinRelContrProcess.BPtk")
save.file(INIT_clas.bin,prefix=prefix,folder=save.wd, filename = "OTUBinClass")
save.file(INIT_bin.clas,prefix=prefix,folder=save.wd, filename = "BinTopOTU")
save.file(INIT_Binwt,prefix=prefix,folder=save.wd, filename = "BinRelAbundance")

```


### genus abundance for iToL

``` {r PhaCmessage=F, echo=T, eval=T, warning=F, include=T, cache=T}

# agglomerate taxa to genus level
psdata_INIT_genus <- psdata_INIT %>%
  tax_glom(., "Genus")

library(ape)

# save new tree
new_tree <- phy_tree(psdata_INIT_genus)

# Save to Newick format
write.tree(new_tree, file = paste0(save.wd, "/YXIN_INIT_genus_output_tree.newick"))

# melt the phyloseq object into a df-like structure
ps_genus <- psmelt(psdata_INIT_genus)

# count n genera n = 426
ps_genus %>% 
  as_tibble() %>% 
  mutate(Genus = factor(Genus)) %>% 
  pull(Genus) %>% 
  levels() %>% 
  length() %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )
  

# add column ASV to the INIT_clas.bin
INIT_clas.bin_genus <- INIT_clas.bin %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV, Bin, Genus) %>%
  mutate(Bin = tolower(Bin))

# merge ASV and Bin data
ASV_table <- tax_table(psdata_INIT_genus) %>%
  as.data.frame() %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV) %>%
  left_join(INIT_clas.bin_genus, by = "ASV") %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )
  
# Loop

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)

for (grp in source_list) {
    
  # Filter and normalize abundance within each Sample
  abundance_list[[grp]] <- ps_genus %>% 
    filter(sludge_source == grp) %>% 
    select(Sample, Abundance, Genus) %>%
    left_join(ASV_table, by = "Genus") %>%
    group_by(Sample, Genus) %>%
    summarise(Abundance = sum(Abundance), .groups = "drop_last") %>%
    mutate(Abundance = Abundance / sum(Abundance) * 100) %>%
    ungroup() %>%
    mutate(SludgeSource = grp) %>%
    left_join(ASV_table, by = "Genus")
}

# Combine to one long data frame
abundance_all <- bind_rows(abundance_list)

# Or save as TSV
write.table(abundance_all, paste0(save.wd, "/YXIN_0h_genus_abundances.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)

```

### Preparing comm assembly data for iToL
``` {r extract phylo tree for iToL, message=F, echo=T, eval=T, warning=F, include=T, cache=T}}

Ptk_list <- list()
group_list <- unique(INIT_Ptk$Group)

for (grp in group_list) {
  Ptk_list[[grp]] <- INIT_Ptk %>%
    as.data.frame() %>%
    filter(Index %in% c("HeS", "HoS", "DL", "HD", "DR")) %>%
    filter(Group == grp) %>%
    pivot_longer(cols = 5:ncol(.),
                 names_to = "Bin",
                 values_to = "Importance") %>%
    pivot_wider(names_from = "Index",
                values_from = "Importance") %>%
    select(Bin:DR) %>%
    mutate(Group = grp) %>%
    right_join(ASV_table, by = "Bin")
}

# Combine if needed
Ptk_all <- bind_rows(Ptk_list)

# Or save as TSV
write.table(Ptk_all, paste0(save.wd, "/YXIN_0h_ProcImp_iToL.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)


```


## iToL data with genus ID as tip labels

``` {r}

# Get unique Bin names
Bin_names <- unique(ASV_table$Bin)

# Generate distinct colors for each Bin
# You can use RColorBrewer, viridis, or base colors
library(RColorBrewer)
n_bins <- length(Bin_names)
color_vector <- brewer.pal(min(n_bins, 8), "Set2")  # Use Set2 palette (up to 8 colors)
if (n_bins > 8) {
  # If more than 8 bins, extend using colorRampPalette
  color_vector <- colorRampPalette(brewer.pal(8, "Set2"))(n_bins)
}

# Create a named vector
bin_colors <- setNames(color_vector, Bin_names)
bin_colors_df <- tibble(Bin = names(bin_colors), color = unname(bin_colors))

# Build legend lines for iTOL format
legend_colors <- paste(unname(bin_colors), collapse = "\t")
legend_labels <- paste(names(bin_colors), collapse = "\t")


# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tGenus_Bins",
  "LEGEND_TITLE\tBins",
  glue("LEGEND_COLORS\t{legend_colors}"),
  glue("LEGEND_LABELS\t{legend_labels}"),
  "DATA"
)

# Join color info into your data
df <- ASV_table %>%
  left_join(bin_colors_df, by = "Bin") %>%
  select(Genus, color, Bin)

# Set the output path
output_file <- glue("{save.wd}/iToL_Bins_og_genusID.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)

#####################################################
# Relative importance

relImp_list <- list()
grp_list <- unique(Ptk_all$Group)

for (grp in grp_list) {
  df <- Ptk_all %>%
    filter(Group == grp) %>%
    select(Genus, HeS:DR) %>%
    left_join(ASV_table, by = "Genus" ) %>%
    select(Genus, HeS:DR)
    
  # Get dynamic sample names
  index_cols <- colnames(df)[-1]  # Assuming ASV is the first column
  index_labels <- paste(index_cols, collapse = "\t")
      
  # Create header lines with glue for dynamic text
  header_lines <- c(
    "DATASET_MULTIBAR",
    "SEPARATOR\tTAB",
    glue("DATASET_LABEL\tProcess Relative Importance {grp}"),
    glue("FIELD_LABELS\t{index_labels}"),
    "FIELD_COLORS\t#FFEE58\t#7492CF\t#FFA000\t#D0D1E6\t#21455e",
    "DATASET_SCALE\t100\t100\t100\t100\t100",
    "DATA"
  )
    
  # Set the output path
  output_file <- glue("{save.wd}/iToL_{grp}_relImp_og_genusID.tsv")
    
  # Write header and data
  writeLines(header_lines, con = output_file)
  write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
  # Store to list if needed
  relImp_list[[grp]] <- df
  }

#########################################################

# Heatmap for genus abundance per sample

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)
substrate_list <- unique(ps_genus$substrate)

for (grp in source_list) {
    
  df <- ASV_table %>%
    left_join(abundance_all, by = "Genus") %>%
    filter(SludgeSource == grp) %>%
    select(Genus, Sample, Abundance) %>%
    pivot_wider(names_from = Sample, values_from = Abundance)

  # Get dynamic sample names
  sample_cols <- colnames(df)[-1]  # Assuming ASV is the first column
  sample_labels <- paste(sample_cols, collapse = "\t")
    
  # Create header lines with glue for dynamic text
  header_lines <- c(
    "DATASET_HEATMAP",
    "SEPARATOR\tTAB",
    glue("DATASET_LABEL\tabundance per sample {grp}"),
    glue("FIELD_LABELS\t{sample_labels}"),
    "COLOR_MIN\t#FFFFFF",
    "COLOR_MAX\t#FF0000",
    "USE_MID_COLOR\t1",
    "COLOR_MID\t#FF8080",
    "DATA"
  )
    
  # Set the output path
  output_file <- glue("{save.wd}/iToL_{grp}_abundance_og_genusID.tsv")
    
  # Write header and data
  writeLines(header_lines, con = output_file)
  write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
  # Store to list if needed
    abundance_list[[grp]] <- df
}


##################################

# Phac Status

phac <- read_tsv(here("data", "processed", "for_iCAMP", "PhaC_kegg_gtdb_ver16June.txt"))

phac_status <- c("YES", "Unknown")
phac_col <- c("#81C784", "#E0E0E0")

df <- phac %>%
  left_join(ASV_table, by = "Genus") %>%
  mutate(color = case_when(
    PhaC_status == "YES" ~ phac_col[1],
    PhaC_status == "Unknown" ~ phac_col[2])) %>%
  select(Genus, color, PhaC_status)

# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tPhaC16June",
  "LEGEND_TITLE\tPhaC status",
  glue("LEGEND_COLORS\t{glue_collapse(phac_col, sep = '\t')}"),
  glue("LEGEND_LABELS\t{glue_collapse(phac_status, sep = '\t')}"),
  "DATA"
)

# Set the output path
output_file <- glue("{save.wd}/iToL_PhaC_status_genusID.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)



```

