---
title: "Community Assembly Analysis with iCAMP"
author: "ENAT"
date: "2025-06-09"
output: html_document
---

# Community assembly analysis with iCAMP
## Project info
```{r , eval=TRUE, echo=T, include=T, message=FALSE, warning=FALSE}

library(here)

# set optional parameters
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE, 
                      root.dir = here())
options(scipen = 999, digits = 3)

```

```{r loading libraries, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

## load required packages
library(Hmisc)
library(phyloseq)
library(qiime2R)
library(tidyverse)
library(magrittr)
library(devtools)
library(qiime2R)
library(here)
library(breakaway)
library(DivNet)
library(ape)
library(vegan)
library(ggtext)
library(cowplot)
library(RColorBrewer)
library(microbiome)
library(lme4)
library(lmerTest)
library(decontam)
library(glue)
library(lubridate)
library(DECIPHER)
library(ensembleTax)
library(ggh4x)
library(RColorBrewer)
library(dplyr)


library(iCAMP)
library(permute)
library(bigmemory)
library(nortest)
library(minpack.lm)
library(DirichletReg)
library(data.table)
library(NST)
library(RVAideMemoire)

source(here("scripts", "iCAMP", "handytool.r"))

```

## iCAMP analysis (t=48h)

### key parameter settings
``` {r key parameters setting, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

prefix = "YXIN_48h" # prefix of the output file names. usually use a project ID.
save.wd <- here("results", "output_data", "iCAMP_48h")
rand.time = 250 # randomization time, 1000 is usually enough.
nworker=1 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
memory.G=50 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.

```

### Select data: samples from t=48h
``` {r input data preparation, message=F, echo=T, eval=T, warning=T, include=T, cache=F}

psdata_AB <- readRDS(here("data", "processed" , "for_iCAMP", "YXIN_psdata_AlmereBath.rds"))

psdata_AB48 <- 
  prune_taxa(
      taxa_sums(
        subset_samples(psdata_AB, time == "48h"))>0, 
        subset_samples(psdata_AB, time == "48h"))

comm <- t(as.data.frame(otu_table(psdata_AB48)))
clas <- as.data.frame(tax_table(psdata_AB48))
treat <- as(sample_data(psdata_AB48), "data.frame") %>%
  select(sludge_source, substrate) %>%
  mutate(exp = substr(rownames(.), 1, 4)) %>%
  mutate(exp.source = paste(exp, sludge_source, sep = "_")) %>%
  mutate(exp.source.substrate = paste(exp, sludge_source, substrate, sep = "_"))
tree <- phy_tree(psdata_AB48)

```

### Match sample IDs in OTU table and treatment information table

``` {r merge seqs & metadata, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

sampid.check = match.name(rn.list=list(comm=comm, treat=treat))
# for the example data, the output should be All match very well.
# for your data files, if you have not matched their IDs, the unmatched samples will be removed.
treat = sampid.check$treat
comm = sampid.check$comm
comm = comm[,colSums(comm)>0,drop=FALSE] # if some unmatched samples were removed, some OTUs may become ghosts, then you may use this line to remove them if necessary.

```

### Match OTU IDs in OTU table and tree file

``` {r match OTUs table with tree, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

spid.check = match.name(cn.list=list(comm=comm), rn.list = list(clas=clas),
                         tree.list = list(tree=tree))
# for the example data, the output should be "All match very well".
# for your data files, if you have not matched the IDs before, the unmatched OTUs will be removed.
comm = spid.check$comm
clas = spid.check$clas
tree = spid.check$tree

```

### Calculate pairwise phylogenetic distance matrix.

``` {r calculate phylogenetic distance matrix, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

# since microbial community data usually has a large number of species (OTUs or ASVs), we use "big.matrix" in R package "bigmemory" to handle the large phylogenetic distance matrix. 

dir.create(here("results", "output_data", "iCAMP_48h"), recursive = TRUE)
save.wd <- here("results", "output_data", "iCAMP_48h")

setwd(save.wd)
if(!file.exists("pd.desc"))  # pd is short for phylogenetic distance
{
  pd.big = iCAMP::pdist.big(tree = tree, wd=save.wd, nworker = nworker, memory.G = memory.G)
  # output files:
  # path.rda: a R object to list all the nodes and  edge lengthes from root to every tip. saved in R data format. an intermediate output when claculating phylogenetic distance matrix.
  # pd.bin: BIN file (backingfile) generated by function big.matrix in R package bigmemory. This is the big matrix storing pairwise phylogenetic distance values. By using this bigmemory format file, we will not need memory but hard disk when calling big matrix for calculation.
  # pd.desc: the DESC file (descriptorfile) to hold the backingfile (pd.bin) description.
  # pd.taxon.name.csv: comma delimited csv file storing the IDs of tree tips (OTUs), serving as the row/column names of the big phylogenetic distance matrix.
}else{
  # if you already calculated the phylogenetic distance matrix in a previous run
  pd.big = list()
  pd.big$tip.label = read.csv(paste0(save.wd,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
  pd.big$pd.wd = save.wd
  pd.big$pd.file = "pd.desc"
  pd.big$pd.name.file = "pd.taxon.name.csv"
}

```

### Estimate community assembly process with pNST to choose the best nmin

```{r, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

# pNST
prefixj=paste0(prefix,".pNST")
treat.use=treat[,"exp.source",drop=FALSE]
pnstout=NST::pNST(comm=comm, pd.desc=pd.big$pd.file,
                  pd.wd=pd.big$pd.wd, pd.spname=pd.big$tip.label,
                  group=treat.use, abundance.weighted=TRUE,
                  rand=1000,output.rand=FALSE, taxo.null.model="PF",
                  phylo.shuffle=TRUE, nworker=nworker,
                  between.group=TRUE, SES=TRUE,RC=TRUE)
save(pnstout,file = here("results", "output_data", "iCAMP_48h", paste0(prefixj,".detail.rda")))
save.file(pnstout$index.grp,prefix=prefix, folder = save.wd, filename = "group.summary")
save.file(pnstout$index.pair.grp,prefix=prefix,folder = save.wd, filename = "pairwise")

```

### calculate iCAMP result (t=48h)
``` {r iCAMP analysis, message=F, echo=T, eval=T, warning=F, include=T, cache=T}


bin.size.limit = 24 # For real data, usually use a proper number according to phylogenetic signal test or try some settings then choose the reasonable stochasticity level. our experience is 12, or 24, or 48. 
sig.index="SES.RC" # see other options in help document of icamp.big.
AB_icres=iCAMP::icamp.big(comm=comm, pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label,
                       pd.wd = pd.big$pd.wd, rand = rand.time, tree=tree,
                       prefix = prefix, ds = 0.2, pd.cut = NA, sp.check = TRUE,
                       phylo.rand.scale = "within.bin", taxa.rand.scale = "across.all",
                       phylo.metric = "bMPD", sig.index=sig.index, bin.size.limit = bin.size.limit, 
                       nworker = nworker, memory.G = memory.G, rtree.save = FALSE, detail.save = TRUE, 
                       qp.save = FALSE, detail.null = TRUE, ignore.zero = TRUE, output.wd = save.wd, 
                       correct.special = TRUE, unit.sum = rowSums(comm), special.method = "Simple",
                       ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",meta.ab = NULL)

save.file(AB_icres$bNRIiRCa,prefix=prefix, folder= save.wd, filename = "AB_ProcessImp.Pairwise.bNRIi.RCa")

```

### iCAMP bin-level statistics 
```{r iCAMP bin-level stats, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

treat.AB=treat[,"exp.source.substrate",drop=FALSE]
treats=data.frame(CountAll="All", treat.AB,stringsAsFactors = FALSE)
AB_icbin=icamp.bins(icamp.detail = AB_icres$detail,treat = treats,
                 clas = clas,boot = TRUE, rand.time = 1000)
save(AB_icbin,file = here("results", "output_data", "iCAMP_48h", paste0(prefix, "_iCAMPBinSummaryDetail.rda")))

AB_Ptk=AB_icbin$Ptk
AB_BPtk=AB_icbin$BPtk
AB_BRPtk=AB_icbin$BRPtk
AB_clas.bin=AB_icbin$Class.Bin
AB_bin.clas=AB_icbin$Bin.TopClass
AB_Binwt=AB_icbin$Binwt

save.file(AB_Ptk,prefix=prefix,folder=save.wd, filename = "ProcessImpBin.Ptk", )
save.file(AB_BPtk,prefix=prefix, folder=save.wd, filename = "BinContrProcess.BPtk")
save.file(AB_BRPtk,prefix=prefix, folder=save.wd, filename = "BinRelContrProcess.BRPtk")
save.file(AB_clas.bin,prefix=prefix,folder=save.wd, filename = "OTUBinClass")
save.file(AB_bin.clas,prefix=prefix,folder=save.wd, filename = "BinTopOTU")
save.file(AB_Binwt,prefix=prefix,folder=save.wd, filename = "BinRelAbundance")
```


### genus abundance for iToL

``` {r PhaCmessage=F, echo=T, eval=T, warning=F, include=T, cache=T}

# agglomerate taxa to genus level
psdata_AB_genus <- psdata_AB48 %>%
  tax_glom(., "Genus")

library(ape)

# save new tree
new_tree <- phy_tree(psdata_AB_genus)

# Save the data for making PhaC list
saveRDS(psdata_AB_genus, file = here("data", "processed", "for_iCAMP", "YXIN_psdata_AB_genus.rds"))

# Save to Newick format
write.tree(new_tree, file = paste0(save.wd, "/YXIN_AB_genus_output_tree.newick"))

# add column ASV to the AB_clas.bin
AB_clas.bin_genus <- AB_clas.bin %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV, Bin, Genus) %>%
  mutate(Bin = tolower(Bin))

# melt the phyloseq object into a df-like structure
ps_genus <- psmelt(psdata_AB_genus) %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )


# count n genera n = 426
ps_genus %>% 
  as_tibble() %>% 
  mutate(Genus = factor(Genus)) %>% 
  pull(Genus) %>% 
  levels() %>% 
  length() 
  
# merge ASV and Bin data
ASV_table <- tax_table(psdata_AB_genus) %>%
  as.data.frame() %>%
  mutate(ASV = rownames(.)) %>%
  select(ASV) %>%
  left_join(AB_clas.bin_genus, by = "ASV") %>%
  mutate(Genus = Genus %>%
           # Remove content in square brackets (including brackets)
           str_remove_all("\\[.*?\\]") %>%
           # Replace space with "_" if there are 2+ words
           if_else(str_count(., "\\s+") >= 1, str_replace_all(., " ", "_"), .) %>%
           # Replace "(" with "-"
           str_replace_all("\\(", "-") %>%
           # Handle ")": remove if at end, replace with "-" otherwise
           str_replace_all("\\)(?=$)", "") %>%         # Remove if at end
           str_replace_all("\\)", "-")                 # Replace other occurrences
         )
  
# Loop

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)
substrate_list <- unique(ps_genus$substrate)

for (grp in source_list) {
  for (subs in substrate_list) {
    # Create a unique key for each combination
    list_key <- paste(grp, subs, sep = "_")
    
    # Filter and normalize abundance within each Sample
    abundance_list[[list_key]] <- ps_genus %>% 
      filter(sludge_source == grp, substrate == subs) %>% 
      select(Sample, Abundance, Genus) %>%
      left_join(ASV_table, by = "Genus") %>%
      group_by(Sample, Genus) %>%
      summarise(Abundance = sum(Abundance), .groups = "drop_last") %>%
      mutate(Abundance = Abundance / sum(Abundance) * 100) %>%
      ungroup() %>%
      mutate(SludgeSource = grp, Substrate = subs) %>%
      left_join(ASV_table, by = "Genus")
  }
}

# Combine to one long data frame
abundance_all <- bind_rows(abundance_list)

# Or save as TSV
write.table(abundance_all, paste0(save.wd, "/YXIN_AB_genus_abundances.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)

```

### Preparing comm assembly data for iToL
``` {r extract phylo tree for iToL, message=F, echo=T, eval=T, warning=F, include=T, cache=T}}


Ptk_list <- list()
group_list <- unique(AB_Ptk$Group)

for (grp in group_list) {
  Ptk_list[[grp]] <- AB_Ptk %>%
    as.data.frame() %>%
    filter(Index %in% c("HeS", "HoS", "DL", "HD", "DR")) %>%
    filter(Group == grp) %>%
    pivot_longer(cols = 5:ncol(.),
                 names_to = "Bin",
                 values_to = "Importance") %>%
    pivot_wider(names_from = "Index",
                values_from = "Importance") %>%
    select(Bin:DR) %>%
    mutate(Group = grp) %>%
    right_join(ASV_table, by = "Bin")
}

# Combine if needed
Ptk_all <- bind_rows(Ptk_list)

# Or save as TSV
write.table(Ptk_all, paste0(save.wd, "/YXIN_48h_ProcImp_iToL.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)


```


``` {r PhaC, message=F, echo=T, eval=T, warning=F, include=T, cache=T}

phac <- read_tsv(here("data", "processed", "for_iCAMP", "PhaC_kegg_gtdb.txt"))

phac_data <- tax_table(psdata_AB_genus) %>%
  as.data.frame() %>%
  mutate(ASV = rownames(.)) %>%
  left_join(., phac, by = "Genus" )

# save the data for iToL
write.table(phac_data, file = glue(save.wd, "/AB_phac_genus_level.tsv"), sep = "\t", quote = FALSE, row.names = FALSE)

```


### iToL data with genus ID as tip labels

``` {r iToL format }

# Get unique Bin names
Bin_names <- unique(ASV_table$Bin)

# Generate distinct colors for each Bin
# You can use RColorBrewer, viridis, or base colors
library(RColorBrewer)
n_bins <- length(Bin_names)
color_vector <- brewer.pal(min(n_bins, 8), "Set2")  # Use Set2 palette (up to 8 colors)
if (n_bins > 8) {
  # If more than 8 bins, extend using colorRampPalette
  color_vector <- colorRampPalette(brewer.pal(8, "Set2"))(n_bins)
}

# Create a named vector
bin_colors <- setNames(color_vector, Bin_names)
bin_colors_df <- tibble(Bin = names(bin_colors), color = unname(bin_colors))

# Build legend lines for iTOL format
legend_colors <- paste(unname(bin_colors), collapse = "\t")
legend_labels <- paste(names(bin_colors), collapse = "\t")


# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tGenus_Bins",
  "LEGEND_TITLE\tBins",
  glue("LEGEND_COLORS\t{legend_colors}"),
  glue("LEGEND_LABELS\t{legend_labels}"),
  "DATA"
)

# Join color info into your data
df <- ASV_table %>%
  left_join(bin_colors_df, by = "Bin") %>%
  select(Genus, color, Bin)

# Set the output path
output_file <- glue("{save.wd}/iToL_Bins_og_genusID.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)

#####################################################
# Relative importance

relImp_list <- list()
grp_list <- unique(Ptk_all$Group)

for (grp in grp_list) {
  df <- Ptk_all %>%
    filter(Group == grp) %>%
    select(ASV, HeS:DR) %>%
    left_join(ASV_table, by = "ASV" ) %>%
    select(Genus, HeS:DR)
    
  # Get dynamic sample names
  index_cols <- colnames(df)[-1]  # Assuming ASV is the first column
  index_labels <- paste(index_cols, collapse = "\t")
      
  # Create header lines with glue for dynamic text
  header_lines <- c(
    "DATASET_MULTIBAR",
    "SEPARATOR\tTAB",
    glue("DATASET_LABEL\tProcess Relative Importance {grp}"),
    glue("FIELD_LABELS\t{index_labels}"),
    "FIELD_COLORS\t#FFEE58\t#7492CF\t#FFA000\t#D0D1E6\t#21455e",
    "DATASET_SCALE\t100\t100\t100\t100\t100",
    "DATA"
  )
    
  # Set the output path
  output_file <- glue("{save.wd}/iToL_{grp}_relImp_og_genusID.tsv")
    
  # Write header and data
  writeLines(header_lines, con = output_file)
  write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
  # Store to list if needed
  relImp_list[[grp]] <- df
  }

#########################################################

# Heatmap for genus abundance per sample

abundance_list <- list()
source_list <- unique(ps_genus$sludge_source)
substrate_list <- unique(ps_genus$substrate)

for (grp in source_list) {
  for (subs in substrate_list) {

    # Create a unique key for the list
    list_key <- paste(grp, subs, sep = "_")
    
    df <- abundance_all %>%
      filter(SludgeSource == grp, Substrate == subs) %>%
      select(Genus, Sample, Abundance) %>%
      pivot_wider(names_from = Sample, values_from = Abundance)

    # Get dynamic sample names
    sample_cols <- colnames(df)[-1]  # Assuming ASV is the first column
    sample_labels <- paste(sample_cols, collapse = "\t")
    
    # Create header lines with glue for dynamic text
    header_lines <- c(
      "DATASET_HEATMAP",
      "SEPARATOR\tTAB",
      glue("DATASET_LABEL\tAbundance per sample {grp} {subs}"),
      glue("FIELD_LABELS\t{sample_labels}"),
      "COLOR_MIN\t#FFFFFF",
      "COLOR_MAX\t#FF0000",
      "USE_MID_COLOR\t1",
      "COLOR_MID\t#FF8080",
      "DATA"
    )
    
    # Set the output path
    output_file <- glue("{save.wd}/iToL_{grp}_{subs}_abundance_og_genusID.tsv")
    
    # Write header and data
    writeLines(header_lines, con = output_file)
    write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)
    
    # Store to list if needed
    abundance_list[[list_key]] <- df
  }
}

# Phac Status

phac <- read_tsv(here("data", "processed", "for_iCAMP", "PhaC_kegg_gtdb_ver16June.txt"))

phac_status <- c("YES", "Unknown")
phac_col <- c("#81C784", "#E0E0E0")

df <- phac %>%
  left_join(ASV_table, by = "Genus") %>%
  mutate(color = case_when(
    PhaC_status == "YES" ~ phac_col[1],
    PhaC_status == "Unknown" ~ phac_col[2])) %>%
  select(Genus, color, PhaC_status)

# write a tsv
header_lines <- c(
  "DATASET_COLORSTRIP", 
  "SEPARATOR\tTAB",
  "DATASET_LABEL\tPhaC16June",
  "LEGEND_TITLE\tPhaC status",
  glue("LEGEND_COLORS\t{glue_collapse(phac_col, sep = '\t')}"),
  glue("LEGEND_LABELS\t{glue_collapse(phac_status, sep = '\t')}"),
  "DATA"
)

# Set the output path
output_file <- glue("{save.wd}/iToL_PhaC_status.tsv")

# Write header
write_lines(header_lines, file = output_file)

# Write data (without column names)
write.table(df, file = output_file, sep = "\t", row.names = FALSE, col.names = FALSE, quote = FALSE, append = TRUE)

```





